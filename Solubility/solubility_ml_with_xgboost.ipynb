{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.7 64-bit ('proj_env')",
      "metadata": {
        "interpreter": {
          "hash": "7c60b6fc9aa2a66f6350eb1db0aeb4891e90b74a7fe356963e93b321366276ff"
        }
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7-final"
    },
    "colab": {
      "name": "solubility_ml.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "source": [
        "Importing the required Libraries\n",
        "--------------------------------\n",
        "\n",
        "Make Sure to first create your own virtual environment and install all the libraries from the requirements.txt file\n",
        "\n",
        "`pip install -r requirements.txt`"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfIlUBxBH3fP"
      },
      "source": [
        "import pandas as pd  \n",
        "import numpy as np  \n",
        "import matplotlib.pyplot as plt  \n",
        "from sklearn.model_selection import train_test_split \n",
        "import xgboost as xgb\n",
        "import os\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from ann_visualizer.visualize import ann_viz\n",
        "import keras.utils.vis_utils\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "%matplotlib inline"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "source": [
        "Set your working directory\n",
        "--------------------------\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8VatWY3IPpR"
      },
      "source": [
        "os.chdir('D:\\Documents-Storage\\GitHub\\ML_Liquid\\Solubility')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "source": [
        "Load the dataset\n",
        "----------------\n",
        "\n",
        "Everything should be in your working directory. If it throws an error, check your directory setting"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFlfXC-jH3fS"
      },
      "source": [
        "# read data frame overall\n",
        "df = pd.read_csv(\"aqsol.csv\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "source": [
        "Display the first 5 rows\n",
        "------------------------"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w5r3PIFH3fU",
        "outputId": "f4fe618f-e8ce-4458-a249-e85d8dce249c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "# df.columns\n",
        "df.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    ID                                               Name  \\\n",
              "0  A-3         N,N,N-trimethyloctadecan-1-aminium bromide   \n",
              "1  A-4                           Benzo[cd]indol-2(1H)-one   \n",
              "2  A-5                               4-chlorobenzaldehyde   \n",
              "3  A-8  zinc bis[2-hydroxy-3,5-bis(1-phenylethyl)benzo...   \n",
              "4  A-9  4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}meth...   \n",
              "\n",
              "                                               InChI  \\\n",
              "0  InChI=1S/C21H46N.BrH/c1-5-6-7-8-9-10-11-12-13-...   \n",
              "1  InChI=1S/C11H7NO/c13-11-8-5-1-3-7-4-2-6-9(12-1...   \n",
              "2        InChI=1S/C7H5ClO/c8-7-3-1-6(5-9)2-4-7/h1-5H   \n",
              "3  InChI=1S/2C23H22O3.Zn/c2*1-15(17-9-5-3-6-10-17...   \n",
              "4  InChI=1S/C25H30N2O4/c1-5-20(26(10-22-14-28-22)...   \n",
              "\n",
              "                      InChIKey  \\\n",
              "0  SZEMGTQCPRNXEG-UHFFFAOYSA-M   \n",
              "1  GPYLCFQEKPUWLD-UHFFFAOYSA-N   \n",
              "2  AVPYQKSLYISFPO-UHFFFAOYSA-N   \n",
              "3  XTUPUYCJWKHGSW-UHFFFAOYSA-L   \n",
              "4  FAUAZXVRLVIARB-UHFFFAOYSA-N   \n",
              "\n",
              "                                              SMILES  Solubility   SD  \\\n",
              "0                [Br-].CCCCCCCCCCCCCCCCCC[N+](C)(C)C   -3.616127  0.0   \n",
              "1                               O=C1Nc2cccc3cccc1c23   -3.254767  0.0   \n",
              "2                                    Clc1ccc(C=O)cc1   -2.177078  0.0   \n",
              "3  [Zn++].CC(c1ccccc1)c2cc(C(C)c3ccccc3)c(O)c(c2)...   -3.924409  0.0   \n",
              "4  C1OC1CN(CC2CO2)c3ccc(Cc4ccc(cc4)N(CC5CO5)CC6CO...   -4.662065  0.0   \n",
              "\n",
              "   Ocurrences Group    MolWt  ...  NumRotatableBonds  NumValenceElectrons  \\\n",
              "0           1    G1  392.510  ...               17.0                142.0   \n",
              "1           1    G1  169.183  ...                0.0                 62.0   \n",
              "2           1    G1  140.569  ...                1.0                 46.0   \n",
              "3           1    G1  756.226  ...               10.0                264.0   \n",
              "4           1    G1  422.525  ...               12.0                164.0   \n",
              "\n",
              "   NumAromaticRings  NumSaturatedRings  NumAliphaticRings  RingCount    TPSA  \\\n",
              "0               0.0                0.0                0.0        0.0    0.00   \n",
              "1               2.0                0.0                1.0        3.0   29.10   \n",
              "2               1.0                0.0                0.0        1.0   17.07   \n",
              "3               6.0                0.0                0.0        6.0  120.72   \n",
              "4               2.0                4.0                4.0        6.0   56.60   \n",
              "\n",
              "    LabuteASA      BalabanJ      BertzCT  \n",
              "0  158.520601  0.000000e+00   210.377334  \n",
              "1   75.183563  2.582996e+00   511.229248  \n",
              "2   58.261134  3.009782e+00   202.661065  \n",
              "3  323.755434  2.322963e-07  1964.648666  \n",
              "4  183.183268  1.084427e+00   769.899934  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Name</th>\n      <th>InChI</th>\n      <th>InChIKey</th>\n      <th>SMILES</th>\n      <th>Solubility</th>\n      <th>SD</th>\n      <th>Ocurrences</th>\n      <th>Group</th>\n      <th>MolWt</th>\n      <th>...</th>\n      <th>NumRotatableBonds</th>\n      <th>NumValenceElectrons</th>\n      <th>NumAromaticRings</th>\n      <th>NumSaturatedRings</th>\n      <th>NumAliphaticRings</th>\n      <th>RingCount</th>\n      <th>TPSA</th>\n      <th>LabuteASA</th>\n      <th>BalabanJ</th>\n      <th>BertzCT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A-3</td>\n      <td>N,N,N-trimethyloctadecan-1-aminium bromide</td>\n      <td>InChI=1S/C21H46N.BrH/c1-5-6-7-8-9-10-11-12-13-...</td>\n      <td>SZEMGTQCPRNXEG-UHFFFAOYSA-M</td>\n      <td>[Br-].CCCCCCCCCCCCCCCCCC[N+](C)(C)C</td>\n      <td>-3.616127</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>G1</td>\n      <td>392.510</td>\n      <td>...</td>\n      <td>17.0</td>\n      <td>142.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>158.520601</td>\n      <td>0.000000e+00</td>\n      <td>210.377334</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A-4</td>\n      <td>Benzo[cd]indol-2(1H)-one</td>\n      <td>InChI=1S/C11H7NO/c13-11-8-5-1-3-7-4-2-6-9(12-1...</td>\n      <td>GPYLCFQEKPUWLD-UHFFFAOYSA-N</td>\n      <td>O=C1Nc2cccc3cccc1c23</td>\n      <td>-3.254767</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>G1</td>\n      <td>169.183</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>62.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>29.10</td>\n      <td>75.183563</td>\n      <td>2.582996e+00</td>\n      <td>511.229248</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A-5</td>\n      <td>4-chlorobenzaldehyde</td>\n      <td>InChI=1S/C7H5ClO/c8-7-3-1-6(5-9)2-4-7/h1-5H</td>\n      <td>AVPYQKSLYISFPO-UHFFFAOYSA-N</td>\n      <td>Clc1ccc(C=O)cc1</td>\n      <td>-2.177078</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>G1</td>\n      <td>140.569</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>46.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>17.07</td>\n      <td>58.261134</td>\n      <td>3.009782e+00</td>\n      <td>202.661065</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A-8</td>\n      <td>zinc bis[2-hydroxy-3,5-bis(1-phenylethyl)benzo...</td>\n      <td>InChI=1S/2C23H22O3.Zn/c2*1-15(17-9-5-3-6-10-17...</td>\n      <td>XTUPUYCJWKHGSW-UHFFFAOYSA-L</td>\n      <td>[Zn++].CC(c1ccccc1)c2cc(C(C)c3ccccc3)c(O)c(c2)...</td>\n      <td>-3.924409</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>G1</td>\n      <td>756.226</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>264.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>120.72</td>\n      <td>323.755434</td>\n      <td>2.322963e-07</td>\n      <td>1964.648666</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A-9</td>\n      <td>4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}meth...</td>\n      <td>InChI=1S/C25H30N2O4/c1-5-20(26(10-22-14-28-22)...</td>\n      <td>FAUAZXVRLVIARB-UHFFFAOYSA-N</td>\n      <td>C1OC1CN(CC2CO2)c3ccc(Cc4ccc(cc4)N(CC5CO5)CC6CO...</td>\n      <td>-4.662065</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>G1</td>\n      <td>422.525</td>\n      <td>...</td>\n      <td>12.0</td>\n      <td>164.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>56.60</td>\n      <td>183.183268</td>\n      <td>1.084427e+00</td>\n      <td>769.899934</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 26 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "source": [
        "Select the favourable parameters\n",
        "--------------------------------\n",
        "\n",
        "The Best Parameters are selected on the basis of Phik Correlation to give the highest accuracy"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyZRWimSH3fW"
      },
      "source": [
        "# X - NumHAcceptors, NumHDonors, NumAromaticRings, NumSaturatedRings, NumAliphaticRings, MolMR\n",
        "# Y - Solubility \n",
        "# Merged dataframe to provide pair plot \n",
        "\n",
        "X = df.loc[:, ['MolMR','NumHAcceptors', 'NumHDonors', 'NumAromaticRings', 'NumSaturatedRings', 'NumAliphaticRings','HeavyAtomCount','MolLogP','BalabanJ']]\n",
        "Y = df.loc[:, ['Solubility']]\n",
        "merge = df.loc[:, ['MolMR','MolLogP','BalabanJ','NumHAcceptors', 'NumHDonors', 'NumAromaticRings', 'NumSaturatedRings', 'NumAliphaticRings','HeavyAtomCount','Solubility']]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "source": [
        "Split the new dataset into test and train batches\n",
        "-------------------------------------------------\n",
        "\n",
        "This ensures repeatability between the various models used"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-ubXleuH3fb",
        "outputId": "855d3b09-c5ef-4e26-817f-66d10f8a4904",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "source": [
        "1) Linear Regression:\n",
        "---------------------\n",
        "\n",
        "- A basic regressive model. It doesnt not perform well on large and complex datasets but is overall a decent model for beginners\n",
        "- We score the trained model on itself\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45.528518523060434 %\n"
          ]
        }
      ],
      "source": [
        "regressor = LinearRegression()\n",
        "\n",
        "reg = regressor.fit(X_train, Y_train)\n",
        "\n",
        "print(reg.score (X_train, Y_train) * 100, '%')"
      ]
    },
    {
      "source": [
        "2) XGBoost Regressor:\n",
        "---------------------\n",
        "\n",
        "- XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework.\n",
        "- We use the Regressor variant as we aim at predicting the Aqueous solubility of the compounds\n",
        "- To find the best parameters for the model, we use Grid Search. This essentially take in a grid of parameters and trains the model on each and every one of them.\n",
        "- We compare the accuracy of every set and get the best possible parameters.\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub21PVg3JVLq",
        "outputId": "ae5fbc71-8789-4f22-cbee-8adf4bf83e0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "xgb = xgb.XGBRegressor()\n",
        "\n",
        "parameters = {'nthread':[4],\n",
        "              'objective':['reg:linear'],\n",
        "              'learning_rate': [0.005, 0.01, 0.03, 0.05, .07],\n",
        "              'max_depth': [5, 6, 7],\n",
        "              'min_child_weight': [3, 4, 5],\n",
        "              'silent': [1],\n",
        "              'subsample': [0.7],\n",
        "              'colsample_bytree': [0.7, 0.9, 1.0],\n",
        "              'n_estimators': [500]}\n",
        "\n",
        "xgb_grid = GridSearchCV(xgb,\n",
        "                        parameters,\n",
        "                        cv = 2,\n",
        "                        n_jobs = -1,\n",
        "                        verbose=True)\n",
        "xgb_grid.fit(X_train, Y_train)\n",
        "\n",
        "print('XGBoost Regressor Score is {}'.format(xgb_grid.score(X_train, Y_train)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 135 candidates, totalling 270 fits\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   17.4s\n",
            "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed:  2.4min finished\n",
            "[18:30:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:30:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
            "Parameters: { silent } might not be used.\n",
            "\n",
            "  This may not be accurate due to some parameters are only used in language bindings but\n",
            "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
            "  verification. Please open an issue if you find above cases.\n",
            "\n",
            "\n",
            "XGBoost Regressor Score is 0.8357426529504035\n"
          ]
        }
      ]
    },
    {
      "source": [
        "Getting the Best Parameters\n",
        "---------------------------\n",
        "\n",
        "- This is for us to visualize. "
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_uEuvy7OpN4",
        "outputId": "754c614e-f49a-4aac-951c-b95288eee3c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "xgb_grid.best_params_"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': 0.7,\n",
              " 'learning_rate': 0.01,\n",
              " 'max_depth': 7,\n",
              " 'min_child_weight': 4,\n",
              " 'n_estimators': 500,\n",
              " 'nthread': 4,\n",
              " 'objective': 'reg:linear',\n",
              " 'silent': 1,\n",
              " 'subsample': 0.7}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "source": [
        "3) Neural Network Model:\n",
        "------------------------\n",
        "\n",
        "- Now we enter into Deep Learning Techiniques.\n",
        "- The Neural Network models tries to simulate the working of the human brain and produce models accordingly.\n",
        "- It consists of Neurons whose connections are based on weights and biases.\n",
        "- Its is very flexible and popularly used for Classification, Image Recognition, etc..\n",
        "- We are using it for linear type output."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_5 (Dense)              (None, 128)               1280      \n_________________________________________________________________\ndense_6 (Dense)              (None, 256)               33024     \n_________________________________________________________________\ndense_7 (Dense)              (None, 256)               65792     \n_________________________________________________________________\ndense_8 (Dense)              (None, 256)               65792     \n_________________________________________________________________\ndense_9 (Dense)              (None, 1)                 257       \n=================================================================\nTotal params: 166,145\nTrainable params: 166,145\nNon-trainable params: 0\n_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "NN_model = Sequential()\n",
        "\n",
        "# The Input Layer :\n",
        "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
        "\n",
        "# The Hidden Layers :\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "\n",
        "# The Output Layer :\n",
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
        "\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
        "NN_model.summary()"
      ]
    },
    {
      "source": [
        "Different Visualizations of the Neural Network Model\n",
        "----------------------------------------------------\n",
        "\n",
        "- First, we use the basic `plot_model` from `keras` to visualize the different layers of our model.\n",
        "- Although this is not very fancy to look at, it gives us a basic understand of our model."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "keras.utils.vis_utils.plot_model(NN_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "source": [
        "Third Party library for better visualization of the model\n",
        "---------------------------------------------------------\n",
        "\n",
        "- We are using an open source library called `ann_visualizer` which creates a better visualization of our model.\n",
        "- This library is amazing and produces incredible visualizations.\n",
        "- You can find it on GitHub at `https://github.com/RedaOps/ann-visualizer`"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "ann_viz(NN_model, title=\"My first neural network\")"
      ]
    },
    {
      "source": [
        "Creating a Checkpoint\n",
        "---------------------\n",
        "\n",
        "- We create a checkpoint (basically like a game save) to access previous trains of the model."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint_name = 'model_checkpoints/Weights-{epoch:03d}--{val_loss:.5f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "source": [
        "Training the Neural Network Model:\n",
        "----------------------------------\n",
        "\n",
        "- This might take a while depending on your computer. "
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lute_error: 0.8227\n",
            "\n",
            "Epoch 00409: val_loss did not improve from 0.79022\n",
            "Epoch 410/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4378 - mean_absolute_error: 0.4378 - val_loss: 0.8030 - val_mean_absolute_error: 0.8030\n",
            "\n",
            "Epoch 00410: val_loss did not improve from 0.79022\n",
            "Epoch 411/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4090 - mean_absolute_error: 0.4090 - val_loss: 0.8152 - val_mean_absolute_error: 0.8152\n",
            "\n",
            "Epoch 00411: val_loss did not improve from 0.79022\n",
            "Epoch 412/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4315 - mean_absolute_error: 0.4315 - val_loss: 0.8156 - val_mean_absolute_error: 0.8156\n",
            "\n",
            "Epoch 00412: val_loss did not improve from 0.79022\n",
            "Epoch 413/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4107 - mean_absolute_error: 0.4107 - val_loss: 0.7962 - val_mean_absolute_error: 0.7962\n",
            "\n",
            "Epoch 00413: val_loss did not improve from 0.79022\n",
            "Epoch 414/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4228 - mean_absolute_error: 0.4228 - val_loss: 0.8016 - val_mean_absolute_error: 0.8016\n",
            "\n",
            "Epoch 00414: val_loss did not improve from 0.79022\n",
            "Epoch 415/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4314 - mean_absolute_error: 0.4314 - val_loss: 0.8026 - val_mean_absolute_error: 0.8026\n",
            "\n",
            "Epoch 00415: val_loss did not improve from 0.79022\n",
            "Epoch 416/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4276 - mean_absolute_error: 0.4276 - val_loss: 0.8062 - val_mean_absolute_error: 0.8062\n",
            "\n",
            "Epoch 00416: val_loss did not improve from 0.79022\n",
            "Epoch 417/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4304 - mean_absolute_error: 0.4304 - val_loss: 0.8124 - val_mean_absolute_error: 0.8124\n",
            "\n",
            "Epoch 00417: val_loss did not improve from 0.79022\n",
            "Epoch 418/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4252 - mean_absolute_error: 0.4252 - val_loss: 0.8228 - val_mean_absolute_error: 0.8228\n",
            "\n",
            "Epoch 00418: val_loss did not improve from 0.79022\n",
            "Epoch 419/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4254 - mean_absolute_error: 0.4254 - val_loss: 0.8154 - val_mean_absolute_error: 0.8154\n",
            "\n",
            "Epoch 00419: val_loss did not improve from 0.79022\n",
            "Epoch 420/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4139 - mean_absolute_error: 0.4139 - val_loss: 0.8033 - val_mean_absolute_error: 0.8033\n",
            "\n",
            "Epoch 00420: val_loss did not improve from 0.79022\n",
            "Epoch 421/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4171 - mean_absolute_error: 0.4171 - val_loss: 0.8055 - val_mean_absolute_error: 0.8055\n",
            "\n",
            "Epoch 00421: val_loss did not improve from 0.79022\n",
            "Epoch 422/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4094 - mean_absolute_error: 0.4094 - val_loss: 0.8092 - val_mean_absolute_error: 0.8092\n",
            "\n",
            "Epoch 00422: val_loss did not improve from 0.79022\n",
            "Epoch 423/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4243 - mean_absolute_error: 0.4243 - val_loss: 0.8126 - val_mean_absolute_error: 0.8126\n",
            "\n",
            "Epoch 00423: val_loss did not improve from 0.79022\n",
            "Epoch 424/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4108 - mean_absolute_error: 0.4108 - val_loss: 0.7979 - val_mean_absolute_error: 0.7979\n",
            "\n",
            "Epoch 00424: val_loss did not improve from 0.79022\n",
            "Epoch 425/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4117 - mean_absolute_error: 0.4117 - val_loss: 0.8224 - val_mean_absolute_error: 0.8224\n",
            "\n",
            "Epoch 00425: val_loss did not improve from 0.79022\n",
            "Epoch 426/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4216 - mean_absolute_error: 0.4216 - val_loss: 0.8018 - val_mean_absolute_error: 0.8018\n",
            "\n",
            "Epoch 00426: val_loss did not improve from 0.79022\n",
            "Epoch 427/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4109 - mean_absolute_error: 0.4109 - val_loss: 0.8174 - val_mean_absolute_error: 0.8174\n",
            "\n",
            "Epoch 00427: val_loss did not improve from 0.79022\n",
            "Epoch 428/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4215 - mean_absolute_error: 0.4215 - val_loss: 0.7973 - val_mean_absolute_error: 0.7973\n",
            "\n",
            "Epoch 00428: val_loss did not improve from 0.79022\n",
            "Epoch 429/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4279 - mean_absolute_error: 0.4279 - val_loss: 0.8076 - val_mean_absolute_error: 0.8076\n",
            "\n",
            "Epoch 00429: val_loss did not improve from 0.79022\n",
            "Epoch 430/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4078 - mean_absolute_error: 0.4078 - val_loss: 0.8045 - val_mean_absolute_error: 0.8045\n",
            "\n",
            "Epoch 00430: val_loss did not improve from 0.79022\n",
            "Epoch 431/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4245 - mean_absolute_error: 0.4245 - val_loss: 0.8102 - val_mean_absolute_error: 0.8102\n",
            "\n",
            "Epoch 00431: val_loss did not improve from 0.79022\n",
            "Epoch 432/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4113 - mean_absolute_error: 0.4113 - val_loss: 0.8077 - val_mean_absolute_error: 0.8077\n",
            "\n",
            "Epoch 00432: val_loss did not improve from 0.79022\n",
            "Epoch 433/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4062 - mean_absolute_error: 0.4062 - val_loss: 0.8259 - val_mean_absolute_error: 0.8259\n",
            "\n",
            "Epoch 00433: val_loss did not improve from 0.79022\n",
            "Epoch 434/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4355 - mean_absolute_error: 0.4355 - val_loss: 0.8356 - val_mean_absolute_error: 0.8356\n",
            "\n",
            "Epoch 00434: val_loss did not improve from 0.79022\n",
            "Epoch 435/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4307 - mean_absolute_error: 0.4307 - val_loss: 0.8040 - val_mean_absolute_error: 0.8040\n",
            "\n",
            "Epoch 00435: val_loss did not improve from 0.79022\n",
            "Epoch 436/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4156 - mean_absolute_error: 0.4156 - val_loss: 0.8018 - val_mean_absolute_error: 0.8018\n",
            "\n",
            "Epoch 00436: val_loss did not improve from 0.79022\n",
            "Epoch 437/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4147 - mean_absolute_error: 0.4147 - val_loss: 0.7991 - val_mean_absolute_error: 0.7991\n",
            "\n",
            "Epoch 00437: val_loss did not improve from 0.79022\n",
            "Epoch 438/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4176 - mean_absolute_error: 0.4176 - val_loss: 0.7954 - val_mean_absolute_error: 0.7954\n",
            "\n",
            "Epoch 00438: val_loss did not improve from 0.79022\n",
            "Epoch 439/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4155 - mean_absolute_error: 0.4155 - val_loss: 0.8064 - val_mean_absolute_error: 0.8064\n",
            "\n",
            "Epoch 00439: val_loss did not improve from 0.79022\n",
            "Epoch 440/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4155 - mean_absolute_error: 0.4155 - val_loss: 0.8092 - val_mean_absolute_error: 0.8092\n",
            "\n",
            "Epoch 00440: val_loss did not improve from 0.79022\n",
            "Epoch 441/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4188 - mean_absolute_error: 0.4188 - val_loss: 0.8012 - val_mean_absolute_error: 0.8012\n",
            "\n",
            "Epoch 00441: val_loss did not improve from 0.79022\n",
            "Epoch 442/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4013 - mean_absolute_error: 0.4013 - val_loss: 0.8154 - val_mean_absolute_error: 0.8154\n",
            "\n",
            "Epoch 00442: val_loss did not improve from 0.79022\n",
            "Epoch 443/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4100 - mean_absolute_error: 0.4100 - val_loss: 0.8002 - val_mean_absolute_error: 0.8002\n",
            "\n",
            "Epoch 00443: val_loss did not improve from 0.79022\n",
            "Epoch 444/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4188 - mean_absolute_error: 0.4188 - val_loss: 0.8116 - val_mean_absolute_error: 0.8116\n",
            "\n",
            "Epoch 00444: val_loss did not improve from 0.79022\n",
            "Epoch 445/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4122 - mean_absolute_error: 0.4122 - val_loss: 0.8014 - val_mean_absolute_error: 0.8014\n",
            "\n",
            "Epoch 00445: val_loss did not improve from 0.79022\n",
            "Epoch 446/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3944 - mean_absolute_error: 0.3944 - val_loss: 0.8023 - val_mean_absolute_error: 0.8023\n",
            "\n",
            "Epoch 00446: val_loss did not improve from 0.79022\n",
            "Epoch 447/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4222 - mean_absolute_error: 0.4222 - val_loss: 0.8070 - val_mean_absolute_error: 0.8070\n",
            "\n",
            "Epoch 00447: val_loss did not improve from 0.79022\n",
            "Epoch 448/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4030 - mean_absolute_error: 0.4030 - val_loss: 0.7978 - val_mean_absolute_error: 0.7978\n",
            "\n",
            "Epoch 00448: val_loss did not improve from 0.79022\n",
            "Epoch 449/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4141 - mean_absolute_error: 0.4141 - val_loss: 0.8109 - val_mean_absolute_error: 0.8109\n",
            "\n",
            "Epoch 00449: val_loss did not improve from 0.79022\n",
            "Epoch 450/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4164 - mean_absolute_error: 0.4164 - val_loss: 0.8024 - val_mean_absolute_error: 0.8024\n",
            "\n",
            "Epoch 00450: val_loss did not improve from 0.79022\n",
            "Epoch 451/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4124 - mean_absolute_error: 0.4124 - val_loss: 0.8101 - val_mean_absolute_error: 0.8101\n",
            "\n",
            "Epoch 00451: val_loss did not improve from 0.79022\n",
            "Epoch 452/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4130 - mean_absolute_error: 0.4130 - val_loss: 0.8030 - val_mean_absolute_error: 0.8030\n",
            "\n",
            "Epoch 00452: val_loss did not improve from 0.79022\n",
            "Epoch 453/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4085 - mean_absolute_error: 0.4085 - val_loss: 0.8072 - val_mean_absolute_error: 0.8072\n",
            "\n",
            "Epoch 00453: val_loss did not improve from 0.79022\n",
            "Epoch 454/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4001 - mean_absolute_error: 0.4001 - val_loss: 0.8062 - val_mean_absolute_error: 0.8062\n",
            "\n",
            "Epoch 00454: val_loss did not improve from 0.79022\n",
            "Epoch 455/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4076 - mean_absolute_error: 0.4076 - val_loss: 0.8028 - val_mean_absolute_error: 0.8028\n",
            "\n",
            "Epoch 00455: val_loss did not improve from 0.79022\n",
            "Epoch 456/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3932 - mean_absolute_error: 0.3932 - val_loss: 0.8107 - val_mean_absolute_error: 0.8107\n",
            "\n",
            "Epoch 00456: val_loss did not improve from 0.79022\n",
            "Epoch 457/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4097 - mean_absolute_error: 0.4097 - val_loss: 0.8152 - val_mean_absolute_error: 0.8152\n",
            "\n",
            "Epoch 00457: val_loss did not improve from 0.79022\n",
            "Epoch 458/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4087 - mean_absolute_error: 0.4087 - val_loss: 0.8043 - val_mean_absolute_error: 0.8043\n",
            "\n",
            "Epoch 00458: val_loss did not improve from 0.79022\n",
            "Epoch 459/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4091 - mean_absolute_error: 0.4091 - val_loss: 0.8113 - val_mean_absolute_error: 0.8113\n",
            "\n",
            "Epoch 00459: val_loss did not improve from 0.79022\n",
            "Epoch 460/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4150 - mean_absolute_error: 0.4150 - val_loss: 0.7980 - val_mean_absolute_error: 0.7980\n",
            "\n",
            "Epoch 00460: val_loss did not improve from 0.79022\n",
            "Epoch 461/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4172 - mean_absolute_error: 0.4172 - val_loss: 0.8096 - val_mean_absolute_error: 0.8096\n",
            "\n",
            "Epoch 00461: val_loss did not improve from 0.79022\n",
            "Epoch 462/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4108 - mean_absolute_error: 0.4108 - val_loss: 0.7941 - val_mean_absolute_error: 0.7941\n",
            "\n",
            "Epoch 00462: val_loss did not improve from 0.79022\n",
            "Epoch 463/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3995 - mean_absolute_error: 0.3995 - val_loss: 0.8123 - val_mean_absolute_error: 0.8123\n",
            "\n",
            "Epoch 00463: val_loss did not improve from 0.79022\n",
            "Epoch 464/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4033 - mean_absolute_error: 0.4033 - val_loss: 0.7946 - val_mean_absolute_error: 0.7946\n",
            "\n",
            "Epoch 00464: val_loss did not improve from 0.79022\n",
            "Epoch 465/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4107 - mean_absolute_error: 0.4107 - val_loss: 0.8017 - val_mean_absolute_error: 0.8017\n",
            "\n",
            "Epoch 00465: val_loss did not improve from 0.79022\n",
            "Epoch 466/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4015 - mean_absolute_error: 0.4015 - val_loss: 0.8105 - val_mean_absolute_error: 0.8105\n",
            "\n",
            "Epoch 00466: val_loss did not improve from 0.79022\n",
            "Epoch 467/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3977 - mean_absolute_error: 0.3977 - val_loss: 0.7914 - val_mean_absolute_error: 0.7914\n",
            "\n",
            "Epoch 00467: val_loss did not improve from 0.79022\n",
            "Epoch 468/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4062 - mean_absolute_error: 0.4062 - val_loss: 0.8073 - val_mean_absolute_error: 0.8073\n",
            "\n",
            "Epoch 00468: val_loss did not improve from 0.79022\n",
            "Epoch 469/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3915 - mean_absolute_error: 0.3915 - val_loss: 0.7988 - val_mean_absolute_error: 0.7988\n",
            "\n",
            "Epoch 00469: val_loss did not improve from 0.79022\n",
            "Epoch 470/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3901 - mean_absolute_error: 0.3901 - val_loss: 0.8095 - val_mean_absolute_error: 0.8095\n",
            "\n",
            "Epoch 00470: val_loss did not improve from 0.79022\n",
            "Epoch 471/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3884 - mean_absolute_error: 0.3884 - val_loss: 0.8147 - val_mean_absolute_error: 0.8147\n",
            "\n",
            "Epoch 00471: val_loss did not improve from 0.79022\n",
            "Epoch 472/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4116 - mean_absolute_error: 0.4116 - val_loss: 0.8066 - val_mean_absolute_error: 0.8066\n",
            "\n",
            "Epoch 00472: val_loss did not improve from 0.79022\n",
            "Epoch 473/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3877 - mean_absolute_error: 0.3877 - val_loss: 0.7992 - val_mean_absolute_error: 0.7992\n",
            "\n",
            "Epoch 00473: val_loss did not improve from 0.79022\n",
            "Epoch 474/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4116 - mean_absolute_error: 0.4116 - val_loss: 0.8077 - val_mean_absolute_error: 0.8077\n",
            "\n",
            "Epoch 00474: val_loss did not improve from 0.79022\n",
            "Epoch 475/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3870 - mean_absolute_error: 0.3870 - val_loss: 0.8072 - val_mean_absolute_error: 0.8072\n",
            "\n",
            "Epoch 00475: val_loss did not improve from 0.79022\n",
            "Epoch 476/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3938 - mean_absolute_error: 0.3938 - val_loss: 0.8123 - val_mean_absolute_error: 0.8123\n",
            "\n",
            "Epoch 00476: val_loss did not improve from 0.79022\n",
            "Epoch 477/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3971 - mean_absolute_error: 0.3971 - val_loss: 0.7964 - val_mean_absolute_error: 0.7964\n",
            "\n",
            "Epoch 00477: val_loss did not improve from 0.79022\n",
            "Epoch 478/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3997 - mean_absolute_error: 0.3997 - val_loss: 0.8163 - val_mean_absolute_error: 0.8163\n",
            "\n",
            "Epoch 00478: val_loss did not improve from 0.79022\n",
            "Epoch 479/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4098 - mean_absolute_error: 0.4098 - val_loss: 0.8129 - val_mean_absolute_error: 0.8129\n",
            "\n",
            "Epoch 00479: val_loss did not improve from 0.79022\n",
            "Epoch 480/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3920 - mean_absolute_error: 0.3920 - val_loss: 0.8162 - val_mean_absolute_error: 0.8162\n",
            "\n",
            "Epoch 00480: val_loss did not improve from 0.79022\n",
            "Epoch 481/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4027 - mean_absolute_error: 0.4027 - val_loss: 0.8087 - val_mean_absolute_error: 0.8087\n",
            "\n",
            "Epoch 00481: val_loss did not improve from 0.79022\n",
            "Epoch 482/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4039 - mean_absolute_error: 0.4039 - val_loss: 0.8025 - val_mean_absolute_error: 0.8025\n",
            "\n",
            "Epoch 00482: val_loss did not improve from 0.79022\n",
            "Epoch 483/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4021 - mean_absolute_error: 0.4021 - val_loss: 0.8313 - val_mean_absolute_error: 0.8313\n",
            "\n",
            "Epoch 00483: val_loss did not improve from 0.79022\n",
            "Epoch 484/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4053 - mean_absolute_error: 0.4053 - val_loss: 0.8109 - val_mean_absolute_error: 0.8109\n",
            "\n",
            "Epoch 00484: val_loss did not improve from 0.79022\n",
            "Epoch 485/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3957 - mean_absolute_error: 0.3957 - val_loss: 0.8048 - val_mean_absolute_error: 0.8048\n",
            "\n",
            "Epoch 00485: val_loss did not improve from 0.79022\n",
            "Epoch 486/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4034 - mean_absolute_error: 0.4034 - val_loss: 0.8065 - val_mean_absolute_error: 0.8065\n",
            "\n",
            "Epoch 00486: val_loss did not improve from 0.79022\n",
            "Epoch 487/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3946 - mean_absolute_error: 0.3946 - val_loss: 0.8266 - val_mean_absolute_error: 0.8266\n",
            "\n",
            "Epoch 00487: val_loss did not improve from 0.79022\n",
            "Epoch 488/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3994 - mean_absolute_error: 0.3994 - val_loss: 0.7999 - val_mean_absolute_error: 0.7999\n",
            "\n",
            "Epoch 00488: val_loss did not improve from 0.79022\n",
            "Epoch 489/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3936 - mean_absolute_error: 0.3936 - val_loss: 0.8057 - val_mean_absolute_error: 0.8057\n",
            "\n",
            "Epoch 00489: val_loss did not improve from 0.79022\n",
            "Epoch 490/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3964 - mean_absolute_error: 0.3964 - val_loss: 0.8048 - val_mean_absolute_error: 0.8048\n",
            "\n",
            "Epoch 00490: val_loss did not improve from 0.79022\n",
            "Epoch 491/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3986 - mean_absolute_error: 0.3986 - val_loss: 0.8093 - val_mean_absolute_error: 0.8093\n",
            "\n",
            "Epoch 00491: val_loss did not improve from 0.79022\n",
            "Epoch 492/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3988 - mean_absolute_error: 0.3988 - val_loss: 0.8116 - val_mean_absolute_error: 0.8116\n",
            "\n",
            "Epoch 00492: val_loss did not improve from 0.79022\n",
            "Epoch 493/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3892 - mean_absolute_error: 0.3892 - val_loss: 0.8021 - val_mean_absolute_error: 0.8021\n",
            "\n",
            "Epoch 00493: val_loss did not improve from 0.79022\n",
            "Epoch 494/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3816 - mean_absolute_error: 0.3816 - val_loss: 0.8047 - val_mean_absolute_error: 0.8047\n",
            "\n",
            "Epoch 00494: val_loss did not improve from 0.79022\n",
            "Epoch 495/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.4000 - mean_absolute_error: 0.4000 - val_loss: 0.8118 - val_mean_absolute_error: 0.8118\n",
            "\n",
            "Epoch 00495: val_loss did not improve from 0.79022\n",
            "Epoch 496/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3932 - mean_absolute_error: 0.3932 - val_loss: 0.8189 - val_mean_absolute_error: 0.8189\n",
            "\n",
            "Epoch 00496: val_loss did not improve from 0.79022\n",
            "Epoch 497/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3946 - mean_absolute_error: 0.3946 - val_loss: 0.8144 - val_mean_absolute_error: 0.8144\n",
            "\n",
            "Epoch 00497: val_loss did not improve from 0.79022\n",
            "Epoch 498/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3858 - mean_absolute_error: 0.3858 - val_loss: 0.8078 - val_mean_absolute_error: 0.8078\n",
            "\n",
            "Epoch 00498: val_loss did not improve from 0.79022\n",
            "Epoch 499/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3859 - mean_absolute_error: 0.3859 - val_loss: 0.8146 - val_mean_absolute_error: 0.8146\n",
            "\n",
            "Epoch 00499: val_loss did not improve from 0.79022\n",
            "Epoch 500/500\n",
            "234/234 [==============================] - 0s 1ms/step - loss: 0.3860 - mean_absolute_error: 0.3860 - val_loss: 0.7968 - val_mean_absolute_error: 0.7968\n",
            "\n",
            "Epoch 00500: val_loss did not improve from 0.79022\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x2267db31e48>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "NN_model.fit(X_train, Y_train, epochs=500, batch_size=32, validation_data=(X_test, Y_test), callbacks=callbacks_list)"
      ]
    },
    {
      "source": [
        "Selecting the best checkpoint file\n",
        "----------------------------------\n",
        "\n",
        "- Make sure to select the checkpoint file with the lowest `val_loss`. \n",
        "- The files are in the format `Weights-<epoch>--<val_loss>.hdf5`\n",
        "- Search for the Highest `epoch` or the lowest `val_loss`"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "weights_file = 'model_checkpoints/Weights-293--0.79022.hdf5' # choose the best checkpoint \n",
        "NN_model.load_weights(weights_file) # load it\n",
        "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
      ]
    },
    {
      "source": [
        "Predicting the test values of all the models\n",
        "--------------------------------------------"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "NN_predictions = NN_model.predict(X_test)\n",
        "\n",
        "LG_pred = regressor.predict(X_test)\n",
        "\n",
        "XGB_pred = xgb_grid.predict(X_test)"
      ]
    },
    {
      "source": [
        "Explained Variance Score of all the three model's test data predictions\n",
        "-----------------------------------------------------------------------"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "NN_score = explained_variance_score(Y_test, NN_predictions)\n",
        "\n",
        "XGB_Score = explained_variance_score(Y_test, xgb_pred)\n",
        "\n",
        "REG_Score = explained_variance_score(Y_test, Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Model's Explained Variance Score is 38.45539171640904 %\n\nXGBoost Regressor with basic GridSearchCV's Explained Variance Score is 72.78709469274276 %\n\nNeural Network Model's Explained Variance Score is 74.46781819518024 %\n"
          ]
        }
      ],
      "source": [
        "print(\"Linear Regression Model's Explained Variance Score is {} %\\n\\nXGBoost Regressor with basic GridSearchCV's Explained Variance Score is {} %\\n\\nNeural Network Model's Explained Variance Score is {} %\".format(REG_Score * 100, XGB_Score * 100, NN_score * 100))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP1tAFVuH3fh",
        "outputId": "f19fc0fa-9bc1-475e-8a23-9b3d174fac23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "# more information about MAE, MSE and RMSE \n",
        "\n",
        "print('Linear Regression Mean Absolute Error:', metrics.mean_absolute_error(Y_test, Y_pred))  \n",
        "print('Linear Regression Mean Squared Error:', metrics.mean_squared_error(Y_test, Y_pred))  \n",
        "print('Linear Regression Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, Y_pred)))\n",
        "print('Mean:', Y_test.mean())\n",
        "print('Linear Regression Mean:', Y_pred.mean())"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Mean Absolute Error: 1.3428191571705763\nLinear Regression Mean Squared Error: 3.4880747284419513\nLinear Regression Root Mean Squared Error: 1.8676388110236817\nMean: Solubility   -2.888173\ndtype: float64\nLinear Regression Mean: -2.8730009392804967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqACzrl0NtfD",
        "outputId": "5192764c-15ad-461f-a3f2-930263dbd045",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "print('Linear Regression Mean Absolute Error:', metrics.mean_absolute_error(Y_test, xgb_pred))  \n",
        "print('Linear Regression Mean Squared Error:', metrics.mean_squared_error(Y_test, xgb_pred))  \n",
        "print('Linear Regression Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, xgb_pred)))\n",
        "print('Mean:', Y_test.mean())\n",
        "print('XGBRegressor Mean:', xgb_pred.mean())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Mean Absolute Error: 0.8680589882769312\nLinear Regression Mean Squared Error: 1.5430253164798824\nLinear Regression Root Mean Squared Error: 1.2421857012861977\nMean: Solubility   -2.888173\ndtype: float64\nXGBRegressor Mean: -2.8595262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBFZvb2VTs9K"
      },
      "source": [
        "yt_score = regressor.score(X_test, Y_test)\n",
        "xgbt_score = xgb_grid.score(X_test, Y_test)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4mRV-ibT5mc",
        "outputId": "e7883128-1ad6-4aed-b6a6-df25fb8bcf3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Test Score of Linear Regression is {} %\\nTest Score of XGBRegressor is {} %\".format(yt_score * 100, xgbt_score * 100))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Score of Linear Regression is 38.45132992367372 %\nTest Score of XGBRegressor is 72.772614259368 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EARgB6tEH3fj"
      },
      "source": [],
      "execution_count": 129,
      "outputs": []
    }
  ]
}